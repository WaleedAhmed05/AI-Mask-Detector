# -*- coding: utf-8 -*-
"""PreProcessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/16VZAtWZhYwfNHY7dzsqpCsrN-KTc0zbZ

## Importing Required Libraries
"""

pip install skorch

import torch 
import torch.nn as nn
import shutil
import torchvision.transforms as transforms
from torch.utils.data import Dataset
from skorch import NeuralNetClassifier
from skorch.callbacks import EpochScoring
from importlib import reload
from skimage import io
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score
from skorch.helper import predefined_split


from google.colab import drive
import matplotlib.pyplot as plt

drive.mount('/content/drive', force_remount=True)
plt=reload(plt)

"""## Setting Paths of Each Class"""

base_path = "/content/drive/MyDrive/Data" 

cloth_mask_path = base_path + "/cloth_mask"
surgical_mask_path = base_path + "/surgical_mask"
no_mask_path = base_path + "/no_mask"
N_95_path = base_path + "/N-95_Mask"
N_95_augmentation_path = base_path + "/N-95_Mask_augmentation"
wrong_worn_mask_path= base_path + "/wrong_worn_mask"

import os #for operating system directories
from os import listdir #for listing all directories/files/images
from PIL import Image #for handling images work.
from PIL import ImageOps #for transforming images into grayscale.
import numpy as np #for doing operations on arrays.

# relative paths to gdrive locations.
# type = class to which this image belongs to.
# gdrive_path = path to which the directories belongs to.
# dimension = dimension of the image
# ctype = color type - [rgb, grayscale].
# returns the tuple of images and corresponding labels.

def load_data(gdrive_path, type, dimension, ctype):
    result = []
    labels = []
    print("gdrive path is " + gdrive_path)
    for images in listdir(gdrive_path):
        image_path = gdrive_path + "/" + images
        #print(image_path)
        image = None
        if ctype == "RGB":
            image = Image.open(image_path).convert(ctype)
        else:
            image = Image.open(image_path)
            image = ImageOps.grayscale(image)
        # resizes the images to the given dimension.
        resized_img = image.resize((dimension))
        data = np.asarray(resized_img)
        result.append(data)
        labels.append(type)
    return (np.array(result), np.array(labels))

"""## Saves the Object into the serialised format"""

import pickle #for storing serialized python object.

# this fn saves the object into the path in serialised format.
# obj - object of some class - in our case it the data which we want to store in the serialised fashion.
def saveSearlisedFilesToDrive(obj, path, fileName):
    # deleteExistingContent(path)
    output_file = open(path + fileName, 'wb')
    pickle.dump(obj, output_file)
    output_file.close()

def combine_tuples(data1, data2):
    (xx,yy) = data1
    (zz,kk) = data2
    X_sample = np.concatenate((xx, zz))
    y_sample = np.concatenate((yy, kk))
    result = (X_sample, y_sample)
    return result

def deleteExistingContent(path):
    if not os.path.exists(path):
        os.makedirs(path)
    shutil.rmtree(path)
    os.mkdir(path)

deleteExistingContent(N_95_augmentation_path)
# SIZE = 128
SIZE= 256
#TODO change resolution to 256 * 256
datagen = ImageDataGenerator(
    rotation_range=45,     #Random rotation between 0 and 45
    width_shift_range=0.2,   #% shift
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    fill_mode="reflect")


image_directory = base_path+"/N-95_Mask"

dataset = []

my_images=os.listdir(image_directory)
for i in my_images:
    path=image_directory+"/"+i
    image = io.imread(path)
    image = Image.fromarray(image, 'RGB')
    image = image.resize((SIZE,SIZE))
    dataset.append(np.array(image))

x = np.array(dataset)

i = 0
for batch in datagen.flow(x, batch_size=30,
                          save_to_dir=base_path+"/N-95_Mask_augmentation",
                          save_prefix='aug',
                          save_format='png'):
    i += 1
    if i > 20:
        break

from sklearn.model_selection import train_test_split #for training and testing data.

# dimension = (256, 256)
dimension = (256, 256)
# data = load_data(cloth_mask_path, 1, dimension = dimension, ctype="RGB")
cloth_mask_data = load_data(cloth_mask_path, 1, dimension = dimension, ctype="RGB")

X_train_cloth, X_test_cloth, y_train_cloth, y_test_cloth = train_test_split(cloth_mask_data[0], cloth_mask_data[1])
#TODO needs to fix split test/train percent.

cloth_train_data = (X_train_cloth, y_train_cloth)
cloth_test_data = (X_test_cloth, y_test_cloth)

saveSearlisedFilesToDrive(cloth_train_data, base_path, "/output/TrainCloth256.pkl")
saveSearlisedFilesToDrive(cloth_test_data, base_path, "/output/TestCloth256.pkl")

surgical_data = load_data(surgical_mask_path, 2, dimension=dimension, ctype="RGB")

X, y = surgical_data
X_train_surgical, X_test_surgical, y_train_surgical, y_test_surgical = train_test_split(X, y)

surgical_train_data = (X_train_surgical, y_train_surgical)
surgical_test_data = (X_test_surgical, y_test_surgical)

saveSearlisedFilesToDrive(surgical_train_data, base_path, "/output/TrainSurgical256.pkl")
saveSearlisedFilesToDrive(surgical_test_data, base_path, "/output/TestSurgical256.pkl")

no_mask_data = load_data(no_mask_path, 3, dimension=dimension, ctype="RGB")

X, y = no_mask_data
X_train_no_mask, X_test_no_mask, y_train_no_mask, y_test_no_mask = train_test_split(X, y)

no_mask_train_data = (X_train_no_mask, y_train_no_mask)
no_mask_test_data = (X_test_no_mask, y_test_no_mask)

saveSearlisedFilesToDrive(no_mask_train_data, base_path, "/output/TrainNoMask256.pkl")
saveSearlisedFilesToDrive(no_mask_test_data, base_path, "/output/TestNoMask256.pkl")

"""## Combines the Tuples of Augmentation and Non-Augmentation Data"""

N_95_data = load_data(N_95_path, 4, dimension=dimension, ctype="RGB")
N_95_augmen_data = load_data(N_95_augmentation_path, 4, dimension=dimension, ctype="RGB")

N_95_finalData = combine_tuples(N_95_data, N_95_augmen_data)

X, y = N_95_finalData
X_train_N_95, X_test_N_95, y_train_N_95, y_test_N_95 = train_test_split(X, y)

N_95_train_data = (X_train_N_95, y_train_N_95)
N_95_test_data=(X_test_N_95, y_test_N_95)

saveSearlisedFilesToDrive(N_95_train_data, base_path, "/output/TrainN_95_256.pkl")
saveSearlisedFilesToDrive(N_95_test_data, base_path, "/output/TestN_95_256.pkl")

wrong_worn_mask_data = load_data(wrong_worn_mask_path, 5, dimension=dimension, ctype="RGB")

X, y = wrong_worn_mask_data
X_train_wrong_worn_mask, X_test_wrong_worn_mask, y_train_wrong_worn_mask, y_test_wrong_worn_mask = train_test_split(X, y)

wrong_worn_train_data = (X_train_wrong_worn_mask, y_train_wrong_worn_mask)
wrong_worn_test_data = (X_test_wrong_worn_mask, y_test_wrong_worn_mask)

saveSearlisedFilesToDrive(wrong_worn_train_data, base_path, "/output/Train_wrong_worn_256.pkl")
saveSearlisedFilesToDrive(wrong_worn_test_data, base_path, "/output/Test_wrong_worn_256.pkl")

"""## Combines the Training and Testing data of the each class into Final Training and Testing."""

X_train_final = np.concatenate((X_train_cloth, X_train_no_mask, X_train_surgical, X_train_N_95,X_train_wrong_worn_mask))
Y_train_final=  np.concatenate((y_train_cloth, y_train_no_mask, y_train_surgical, y_train_N_95,y_train_wrong_worn_mask))
Trainig_Data=(X_train_final,Y_train_final)

X_test_final = np.concatenate((X_test_cloth, X_test_no_mask, X_test_surgical, X_test_N_95,X_test_wrong_worn_mask))
Y_test_final = np.concatenate((y_test_cloth, y_test_no_mask, y_test_surgical, y_test_N_95,y_test_wrong_worn_mask))
Testing_Data=(X_test_final,Y_test_final)

# TODO instead of concatenate use shuffle.
saveSearlisedFilesToDrive(Trainig_Data, base_path, "/output/TrainingFinal.pkl")
saveSearlisedFilesToDrive(Testing_Data, base_path, "/output/TestingFinal.pkl")

(x4,y4)=cloth_mask_data
(x5,y5)=surgical_data
(x6,y6)=no_mask_data
(x7,y7)=wrong_worn_mask_data
(x,y)=N_95_data

X_N_95, y_N_95 = N_95_data
X_aug_N_95, y_aug_N_95 = N_95_augmen_data
X_N_95_final = np.concatenate((X_aug_N_95, X_N_95))

cnt1=len(x4)
cnt3=len(x5)
cnt2=len(x6)
cnt4=len(x7)
cnt5=len(x)

plt.title('Distribution of classes - Before Image Balancing')
plt.rcParams["figure.figsize"] = (5, 5)
plt.bar("cloth_mask", cnt1)
plt.bar("no_mask", cnt2)
plt.bar("surgical_mask", cnt3)
plt.bar("N-95_Mask", cnt5)
plt.bar("Wrong_worn_mask", cnt4)
plt.show()
plt.Figure.clear

plt.Figure.clear
# distribution with augmentation.
(x2,y2)=N_95_augmen_data
cnt1=len(x4)
cnt3=len(x5)
cnt2=len(x6)
cnt5=len(x)
cnt6=len(x2)
N_95_augmen=cnt5+cnt6
plt.title('Distribution of classes - After Image Balancing')
#plt.rcParams["figure.figsize"] = (2, 5)
plt.rcParams["figure.figsize"] = (10,4)
#plt.figure(figsize=(6, 3))
plt.bar("cloth_mask", cnt1)
plt.bar("no_mask", cnt2)
plt.bar("surgical_mask", cnt3)
plt.bar("N-95_Mask",N_95_augmen )
plt.bar("Wrong_worn_mask", cnt4)
plt.show()
plt.clf()
plt.Figure.clear